#!/usr/bin/env python3
"""
Script to force LLM service recreation and test the singleton pattern.
"""

import requests
import time

API_BASE_URL = "http://localhost:8000"

def test_api_connection():
    """Test if the API is accessible."""
    try:
        response = requests.get(f"{API_BASE_URL}/api/health", timeout=5)
        return response.status_code == 200
    except:
        return False

def force_llm_service_recreation():
    """Force the creation of a new LLM service instance."""
    print("ğŸ”„ Forcing LLM Service Recreation")
    print("=" * 50)
    
    if not test_api_connection():
        print("âŒ Cannot connect to API server. Please start the backend first.")
        return False
    
    try:
        # Step 1: Update model to force a change
        print("1. Updating model to 'huihui_ai/gemma3'...")
        update_data = {"ollama_model": "huihui_ai/gemma3"}
        response = requests.put(f"{API_BASE_URL}/api/config/llm", json=update_data)
        if response.status_code == 200:
            print("   âœ… Model update successful")
        else:
            print(f"   âŒ Model update failed: {response.status_code}")
            return False
        
        # Step 2: Trigger LLM service usage by uploading a test image
        print("2. Triggering LLM service usage...")
        print("   ğŸ’¡ We need to trigger an analysis operation to force LLM service creation")
        print("   ğŸ’¡ Options:")
        print("   ğŸ’¡   a) Upload an image via the UI")
        print("   ğŸ’¡   b) Start indexing operation")
        print("   ğŸ’¡   c) Use the search endpoint (if it triggers LLM)")
        print("")
        print("   ğŸ” After triggering, check server logs for:")
        print("   ğŸ”   - 'ğŸ” Creating NEW LLM service singleton instance'")
        print("   ğŸ”   - 'ğŸ” LLM service __init__ starting initialization...'")
        print("   ğŸ”   - 'ğŸ” LLM service model property accessed, returning: huihui_ai/gemma3'")
        print("   ğŸ”   - 'LLM service initialized with model: huihui_ai/gemma3'")
        print("   ğŸ”   - 'ğŸ¤– Calling Ollama API with model: huihui_ai/gemma3'")
        
        return True
        
    except Exception as e:
        print(f"âŒ Failed to force recreation: {e}")
        return False

def check_current_status():
    """Check the current model status."""
    print("\nğŸ“‹ Current Status Check")
    print("=" * 50)
    
    try:
        # Check API configuration
        response = requests.get(f"{API_BASE_URL}/api/config/llm")
        if response.status_code == 200:
            config = response.json()
            current_model = config.get('ollama_model', 'Unknown')
            print(f"   ğŸ“‹ API reports current model: {current_model}")
        else:
            print(f"   âŒ Failed to get config: {response.status_code}")
        
        # Check available models
        response = requests.get(f"{API_BASE_URL}/api/config/ollama/models")
        if response.status_code == 200:
            models_data = response.json()
            available_models = models_data.get('vision_models', [])
            print(f"   ğŸ“Š Available models: {available_models}")
        else:
            print(f"   âŒ Failed to get models: {response.status_code}")
            
    except Exception as e:
        print(f"âŒ Status check failed: {e}")

def main():
    """Main function."""
    print("ğŸ”§ Force LLM Service Recreation Test")
    print("=" * 60)
    
    check_current_status()
    success = force_llm_service_recreation()
    
    print("\nğŸ“ Next Steps:")
    print("=" * 50)
    if success:
        print("âœ… Model updated successfully")
        print("")
        print("ğŸ¯ Now trigger an analysis operation:")
        print("   1. Go to the web UI")
        print("   2. Upload an image OR start indexing")
        print("   3. Watch server logs for singleton debug messages")
        print("")
        print("ğŸ” Expected log sequence:")
        print("   1. 'ğŸ” Creating NEW LLM service singleton instance'")
        print("   2. 'ğŸ” LLM service __init__ starting initialization...'")
        print("   3. 'ğŸ” Initial OLLAMA_MODEL value: huihui_ai/gemma3'")
        print("   4. 'LLM service initialized with model: huihui_ai/gemma3'")
        print("   5. 'ğŸ” LLM service model property accessed, returning: huihui_ai/gemma3'")
        print("   6. 'ğŸ¤– Calling Ollama API with model: huihui_ai/gemma3'")
        print("")
        print("âŒ If you see 'gemma3:4b' instead of 'huihui_ai/gemma3':")
        print("   - Singleton pattern is not working")
        print("   - Settings are not being updated properly")
        print("   - Multiple instances still being created")
    else:
        print("âŒ Failed to update model")
        print("ğŸ”§ Check API connectivity and model availability")

if __name__ == "__main__":
    main()
