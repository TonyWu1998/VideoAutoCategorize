# Local Media Semantic Search Application - MVP Development Plan

## Project Overview

A full-stack application that enables semantic search of locally stored images and videos using AI-powered content analysis. Users can search their media files using natural language queries like "beach sunset" or "family gathering" and get relevant results ranked by semantic similarity.

## System Architecture

### High-Level Architecture
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   React Frontend │    │  Python Backend │    │ Vector Database │
│   (Material-UI)  │◄──►│   (FastAPI)     │◄──►│   (ChromaDB)    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                │
                                ▼
                       ┌─────────────────┐
                       │ Ollama + Gemma3 │
                       │  (Local LLM)    │
                       └─────────────────┘
```

### Component Breakdown

#### 1. Frontend (React + Material-UI)
- **Search Interface**: Clean search bar with filters
- **Media Gallery**: Grid/list view of search results
- **Media Viewer**: Preview modal with metadata display
- **Settings Panel**: Configuration for indexing paths and preferences

#### 2. Backend (Python + FastAPI)
- **Media Indexing Service**: Scans directories and processes files
- **LLM Integration**: Interfaces with Ollama/Gemma3 for content analysis
- **Vector Search API**: Handles semantic search queries
- **File Management**: Serves media files and metadata

#### 3. Database Layer (ChromaDB)
- **Vector Storage**: Embeddings for semantic search
- **Metadata Storage**: File paths, descriptions, tags, timestamps
- **Index Management**: Efficient querying and updates

#### 4. AI Processing (Ollama + Gemma3)
- **Image Analysis**: Extract descriptions and tags from images
- **Video Analysis**: Process video frames for content understanding
- **Embedding Generation**: Create vector representations for search

## Technology Stack

### Frontend
- **Framework**: React 18 with TypeScript
- **UI Library**: Material-UI (MUI) v5
- **State Management**: React Query + Zustand
- **Build Tool**: Vite
- **Styling**: Emotion (built into MUI)

### Backend
- **Framework**: FastAPI (Python 3.11+)
- **LLM Integration**: Ollama Python client
- **Image Processing**: Pillow, OpenCV
- **Video Processing**: FFmpeg-python
- **API Documentation**: Automatic with FastAPI/OpenAPI

### Database
- **Vector DB**: ChromaDB (local, no server required)
- **File Metadata**: SQLite (embedded with ChromaDB)

### AI/ML
- **Local LLM**: Gemma3:4b via Ollama
- **Vision Model**: Built-in vision capabilities of Gemma3
- **Embeddings**: Generated by the vision model

### Development Tools
- **Package Management**: npm/yarn (frontend), pip/poetry (backend)
- **Code Quality**: ESLint, Prettier, Black, mypy
- **Testing**: Jest (frontend), pytest (backend)

## Development Roadmap

### Phase 1: Foundation Setup (Week 1)
- [ ] Set up project structure and development environment
- [ ] Install and configure Ollama with Gemma3:4b
- [ ] Create basic FastAPI backend with health check
- [ ] Set up React frontend with Material-UI
- [ ] Establish ChromaDB connection and basic schema

### Phase 2: Core Backend (Week 2-3)
- [ ] Implement media file discovery and indexing
- [ ] Integrate Ollama for image/video analysis
- [ ] Create vector embeddings and store in ChromaDB
- [ ] Build REST API endpoints for search and metadata
- [ ] Add file serving capabilities

### Phase 3: Frontend Development (Week 3-4)
- [ ] Build search interface with real-time suggestions
- [ ] Create media gallery with lazy loading
- [ ] Implement media preview modal
- [ ] Add settings panel for configuration
- [ ] Integrate with backend APIs

### Phase 4: Integration & Polish (Week 4-5)
- [ ] End-to-end testing and bug fixes
- [ ] Performance optimization
- [ ] Error handling and user feedback
- [ ] Documentation and deployment guides

## Key Features Implementation

### 1. Media Indexing Pipeline
```python
# Pseudocode for indexing process
async def index_media_directory(path: str):
    for file in discover_media_files(path):
        if not already_indexed(file):
            metadata = extract_file_metadata(file)
            description = await analyze_with_llm(file)
            embedding = generate_embedding(description)
            store_in_database(file, metadata, description, embedding)
```

### 2. Semantic Search
```python
# Pseudocode for search
async def semantic_search(query: str, limit: int = 20):
    query_embedding = generate_embedding(query)
    results = vector_db.similarity_search(query_embedding, limit)
    return enrich_with_metadata(results)
```

### 3. Real-time Indexing
- File system watchers for automatic re-indexing
- Background processing queue for new files
- Progress tracking for large directory scans

## Database Schema

### ChromaDB Collections
```python
# Media collection schema
{
    "id": "file_path_hash",
    "metadata": {
        "file_path": "/path/to/file.jpg",
        "file_name": "vacation_beach.jpg",
        "file_size": 2048576,
        "created_date": "2024-01-15T10:30:00Z",
        "modified_date": "2024-01-15T10:30:00Z",
        "media_type": "image",  # image/video
        "dimensions": "1920x1080",
        "duration": null,  # for videos
        "ai_description": "A beautiful sunset over a beach with palm trees",
        "ai_tags": ["beach", "sunset", "palm trees", "ocean"],
        "indexed_date": "2024-01-20T15:45:00Z"
    },
    "embedding": [0.1, 0.2, ...],  # Vector representation
    "document": "beach sunset palm trees ocean beautiful"  # Searchable text
}
```

## API Design

### REST Endpoints
```
GET  /api/health              - Health check
POST /api/index               - Start indexing process
GET  /api/index/status        - Get indexing progress
POST /api/search              - Semantic search
GET  /api/media/{file_id}     - Get media file
GET  /api/metadata/{file_id}  - Get file metadata
POST /api/settings            - Update settings
GET  /api/settings            - Get current settings
```

## Potential Challenges & Solutions

### 1. Performance Issues
**Challenge**: Large media collections causing slow indexing/search
**Solutions**:
- Implement batch processing for indexing
- Use pagination for search results
- Add caching layer for frequent queries
- Optimize vector database configuration

### 2. Memory Usage
**Challenge**: LLM and image processing consuming too much RAM
**Solutions**:
- Process files in batches
- Implement memory monitoring and cleanup
- Use streaming for large video files
- Configure Ollama memory limits

### 3. File Format Support
**Challenge**: Supporting various image/video formats
**Solutions**:
- Use robust libraries (Pillow, OpenCV, FFmpeg)
- Implement format detection and conversion
- Graceful error handling for unsupported formats

### 4. Cross-Platform Compatibility
**Challenge**: Different file systems and paths on Windows/Mac/Linux
**Solutions**:
- Use pathlib for cross-platform path handling
- Test on multiple operating systems
- Handle different file permission models

## Documentation Requirements

### 1. User Documentation
- Installation and setup guide
- User interface walkthrough
- Troubleshooting common issues
- Configuration options

### 2. Developer Documentation
- API reference with examples
- Database schema documentation
- Architecture decision records
- Contributing guidelines

### 3. Deployment Documentation
- System requirements
- Installation scripts
- Configuration management
- Backup and recovery procedures

## Success Metrics

### MVP Success Criteria
- [ ] Successfully index 1000+ media files
- [ ] Search response time < 2 seconds
- [ ] Accurate semantic search results (subjective evaluation)
- [ ] Stable performance with 10GB+ media collections
- [ ] Cross-platform compatibility (Windows, Mac, Linux)

### Performance Targets
- **Indexing Speed**: 10-50 files per minute (depending on file size)
- **Search Latency**: < 500ms for typical queries
- **Memory Usage**: < 4GB during normal operation
- **Storage Overhead**: < 10% of original media size for metadata

## Next Steps

1. **Environment Setup**: Install required tools and dependencies
2. **Project Initialization**: Create repository structure and basic configurations
3. **Proof of Concept**: Build minimal working version with core functionality
4. **Iterative Development**: Follow the roadmap with regular testing and feedback
5. **Documentation**: Maintain comprehensive documentation throughout development

This plan provides a solid foundation for building the MVP while remaining flexible for future enhancements and scalability improvements.
